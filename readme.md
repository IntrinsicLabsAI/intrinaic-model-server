[![Python application](https://github.com/IntrinsicLabsAI/intrinsic-model-server/actions/workflows/python-app.yml/badge.svg)](https://github.com/IntrinsicLabsAI/intrinsic-model-server/actions/workflows/python-app.yml)
[![Frontend build and lint](https://github.com/IntrinsicLabsAI/intrinsic-model-server/actions/workflows/frontend.yml/badge.svg)](https://github.com/IntrinsicLabsAI/intrinsic-model-server/actions/workflows/frontend.yml)
[![Create and publish a Docker image](https://github.com/IntrinsicLabsAI/intrinsic-model-server/actions/workflows/docker.yml/badge.svg)](https://github.com/IntrinsicLabsAI/intrinsic-model-server/actions/workflows/docker.yml)

# Intrinsic Model server

Simple, single-file model server on top of llama.cpp enabled models.


[Checkout our documentation!](https://intrinsiclabsai.github.io/intrinsic-model-server)

## Supported model types

- [x] LLM completion
- [ ] Transcription (coming soon)

